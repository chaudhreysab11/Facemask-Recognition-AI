{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekviHzfp6M5F"
      },
      "outputs": [],
      "source": [
        "#importing neccesary liraries required for reading directiories and images from the dataset\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8jq0NAC6TWJ"
      },
      "outputs": [],
      "source": [
        "#In this section we are building our datastructure for out dataset to be used in our CNN\n",
        "trainingDataset = []\n",
        "classNumber = 0\n",
        "img_size = 150\n",
        "path = \"/content/drive/My Drive/Training\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjtg6Glz6UUW",
        "outputId": "096d00ba-c2b6-430d-b729-0169fb98d516"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "1376\n",
            "2\n",
            "[array([[0.21601307, 0.18986928, 0.19705882, ..., 0.04901961, 0.2006536 ,\n",
            "        0.14542484],\n",
            "       [0.19117647, 0.20196078, 0.20686275, ..., 0.02254902, 0.17647059,\n",
            "        0.15980392],\n",
            "       [0.20098039, 0.2120915 , 0.23104575, ..., 0.17581701, 0.05490196,\n",
            "        0.15424836],\n",
            "       ...,\n",
            "       [0.24869283, 0.24901979, 0.2885621 , ..., 0.01895426, 0.1019612 ,\n",
            "        0.03954261],\n",
            "       [0.25196078, 0.24313725, 0.25980392, ..., 0.05490196, 0.04117647,\n",
            "        0.04705882],\n",
            "       [0.23398689, 0.21764697, 0.23104574, ..., 0.05620916, 0.04607858,\n",
            "        0.05882353]]), 0]\n"
          ]
        }
      ],
      "source": [
        "#clearing the preivously stored dataset from our datastructure\n",
        "trainingDataset.clear()\n",
        "#traversing through all the folders in Training.\n",
        "for folder in (os.listdir(path)):\n",
        "  print(classNumber)\n",
        "  #reading all the images from with_mask and without_mask folders one after another using os library which provides us the functionality to implement operating system.\n",
        "  fp = os.path.join(path,folder)\n",
        "  for eachImage in os.listdir(fp):\n",
        "    imagePath = os.path.join(fp,eachImage)\n",
        "    #Reading each image in grayscale and resizing it to 150x150 so that all the images have same dimension. Because CNN demand all the images to be in same dimension but our data set does containg images with different dimensions so we resize them to same size. \n",
        "    img = (cv2.imread(imagePath,cv2.IMREAD_GRAYSCALE))/255\n",
        "    img_resize = cv2.resize(img, (img_size, img_size))\n",
        "    trainingDataset.append([img_resize,classNumber])\n",
        "  classNumber = classNumber + 1\n",
        "\n",
        "print(len(trainingDataset))\n",
        "print(len(trainingDataset[0]))\n",
        "print(trainingDataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgaQx-eT6Wpr"
      },
      "outputs": [],
      "source": [
        "#All the important libraries required to build up the CNN model are imported here\n",
        "from tensorflow.keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCNHhZT2motJ",
        "outputId": "6736edf9-bb13-44b0-8161-91243563d815"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0]\n"
          ]
        }
      ],
      "source": [
        "X = []\n",
        "Y = []\n",
        "img_size = 150\n",
        "np.random.shuffle(trainingDataset)\n",
        "#Splitting the dataset into feature and labels so that they can act as our x_train and y_train for the CNN\n",
        "for features, label in trainingDataset:\n",
        "    X.append(features)\n",
        "    Y.append(label)\n",
        "print(Y)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQqVdcbWmvxO",
        "outputId": "87381628-f0d6-4f39-a3fd-89df1de42b49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]]\n"
          ]
        }
      ],
      "source": [
        "X = np.array(X).reshape(-1, img_size, img_size, 1)\n",
        "#here we are using one-hot-encoding to map each class to some binary value\n",
        "Y_binary = to_categorical(Y)\n",
        "print(Y_binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbjyrFKA6avN"
      },
      "outputs": [],
      "source": [
        "#Defining sequential model which uses layer after layer to model the cnn network. It works like MLP Classifier.\n",
        "model = Sequential()\n",
        "#Conv2d layer will produces the tensor of output where each output is a feature map which then forwarded for maxpooling.\n",
        "model.add(Conv2D(32, (2, 2), input_shape=(150,150,1)))\n",
        "#Activation function used here is relu which is piecewise linear function.\n",
        "model.add(Activation('relu'))\n",
        "#Maxpool2d will get the maximum value from each block of selected elements from the feature map.\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#Droput layer drops randomly choosen element to 0 in each training cycle. It protects the model from overfitting which is scenerio where the model works good for training data but give poor performance on unseen data\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(64, (2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(128, (2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "#Flatten layer is used for flattering the layers to a single dimension as we can see the previous layers are of two dimension so the flatten layer will flatten the output to a single dimension.\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        " \n",
        "model.add(Dense(2))\n",
        "#softmax activation function maps the value of output between 1 and 0 using probabilistic distribution\n",
        "model.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDQ0j07c6glu"
      },
      "outputs": [],
      "source": [
        "#we use categorial_crossentropy because our data is divided into two catogories,\n",
        "#Optimized is basically the learning algorithm for our model, here the optimizer we used is adam, it give efficient result when used because it converges fast as compared to sgd or others.\n",
        "model.compile(loss='categorial_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'],\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmvqNyBxoUQ7",
        "outputId": "e5175c46-7b42-462a-fc8b-4440fce6c2d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "31/31 [==============================] - 31s 989ms/step - loss: 1.3289 - accuracy: 0.5223 - val_loss: 0.6930 - val_accuracy: 0.5133\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 30s 972ms/step - loss: 0.6833 - accuracy: 0.6739 - val_loss: 0.6860 - val_accuracy: 0.6053\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 30s 979ms/step - loss: 0.6126 - accuracy: 0.6833 - val_loss: 0.5982 - val_accuracy: 0.7094\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 30s 969ms/step - loss: 0.5559 - accuracy: 0.7383 - val_loss: 0.5565 - val_accuracy: 0.8620\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 31s 991ms/step - loss: 0.4395 - accuracy: 0.8027 - val_loss: 0.5773 - val_accuracy: 0.6199\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 30s 978ms/step - loss: 0.3113 - accuracy: 0.8816 - val_loss: 0.6852 - val_accuracy: 0.6441\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 31s 995ms/step - loss: 0.2267 - accuracy: 0.9180 - val_loss: 0.5797 - val_accuracy: 0.7070\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 30s 967ms/step - loss: 0.1954 - accuracy: 0.9346 - val_loss: 0.2664 - val_accuracy: 0.8838\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 30s 979ms/step - loss: 0.1595 - accuracy: 0.9491 - val_loss: 0.3996 - val_accuracy: 0.7893\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 30s 976ms/step - loss: 0.1234 - accuracy: 0.9637 - val_loss: 0.3212 - val_accuracy: 0.8547\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 30s 964ms/step - loss: 0.1667 - accuracy: 0.9335 - val_loss: 0.5024 - val_accuracy: 0.7433\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 30s 965ms/step - loss: 0.0909 - accuracy: 0.9699 - val_loss: 0.3337 - val_accuracy: 0.8475\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 30s 979ms/step - loss: 0.0854 - accuracy: 0.9751 - val_loss: 0.2035 - val_accuracy: 0.9346\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 30s 974ms/step - loss: 0.0646 - accuracy: 0.9792 - val_loss: 0.2284 - val_accuracy: 0.9177\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 31s 1s/step - loss: 0.0519 - accuracy: 0.9813 - val_loss: 0.3157 - val_accuracy: 0.8644\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 30s 979ms/step - loss: 0.0416 - accuracy: 0.9886 - val_loss: 0.3659 - val_accuracy: 0.8329\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 30s 968ms/step - loss: 0.0734 - accuracy: 0.9740 - val_loss: 0.2904 - val_accuracy: 0.8644\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 30s 973ms/step - loss: 0.0333 - accuracy: 0.9917 - val_loss: 0.2101 - val_accuracy: 0.9177\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 30s 984ms/step - loss: 0.0256 - accuracy: 0.9896 - val_loss: 0.2459 - val_accuracy: 0.8935\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 30s 980ms/step - loss: 0.0182 - accuracy: 0.9958 - val_loss: 0.1509 - val_accuracy: 0.9443\n"
          ]
        }
      ],
      "source": [
        "#batch_size refers to the size of data to be used from out dataset in each training cycle.\n",
        "#Epoch is the total number of training cycles to done in our whole training process of the model.\n",
        "#Valiation split is refered as splitting the training data again in validation and after each training cycle the validation test is run over the generated output and checked for verification.\n",
        "model.fit(X, Y_binary,\n",
        "          batch_size = 32,\n",
        "          epochs=20, validation_split = 0.3)\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-HVN7pnqFTw"
      },
      "outputs": [],
      "source": [
        "#This function will process the image and return the required format of the image in which the whole model is being trained.\n",
        "def prepare(filepath):\n",
        "    img_size = 150 \n",
        "    img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)/255  \n",
        "    img_resize = cv2.resize(img, (img_size, img_size))  \n",
        "    return img_resize.reshape(-1, img_size, img_size, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oua0B_BoqJ78",
        "outputId": "668d62fe-6044-4d0f-9cd8-d8abb1ab7d6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.11846361 0.8815364 ]]\n",
            "Without Mask\n"
          ]
        }
      ],
      "source": [
        "#model.predict is used to pridict the picture whether it belongs to with mask class or withou mask class.\n",
        "prediction = model.predict(prepare(\"/content/drive/MyDrive/Training/with_mask/223-with-mask.jpg\"))\n",
        "print((prediction))\n",
        "\n",
        "CATEGORIES = [\"With Mask\", \"Without Mask\"]\n",
        "#the class with maximum probablity will be the category for the image selected above\n",
        "pred_class = CATEGORIES[np.argmax(prediction)]\n",
        "print(pred_class)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}